## Типы асимптотических обозначений в анализе сложности алгоритмов

Асимптотический анализ используется для измерения сложности алгоритма. Он помогает оценить, как ведет себя алгоритм при увеличении размера входных данных. В этом разделе рассмотрим основные виды асимптотических обозначений, которые используются для описания временной и пространственной сложности алгоритмов.

### 1. Верхняя граница (O-большое, Big-O Notation)

**Обозначение O-большое** используется для описания верхней границы времени выполнения алгоритма. Оно указывает на худший случай выполнения алгоритма.

**Определение**: Функция $T(n)$ принадлежит $O(g(n))$, если существуют такие константы $c > 0$ и $n_0 \in \mathbb{N}$, что для всех $n \geq n_0$ выполняется: $T(n) \leq c \cdot g(n)$.

*Пример*: Если $T(n) = 3n^2 + 5n + 7$, то $T(n)$ принадлежит $O(n^2)$, так как можно найти константы $c$ и $n_0$, например $c = 4$ и $n_0 = 1$.

_Достаточное условие:_ Для того, чтобы $T(n)$ принадлежит $O(g(n))$, достаточно чтобы $\lim_{n \to \infty} \frac{T(n)}{g(n)} = c$.

**Доказательство:** Если выражение имеет конечный предел, то оно ограничено (по определению предела функции):
Дано: $$\lim_{n \to \infty} \frac{T(n)}{g(n)} = c,$$ где $c > 0$. Это означает, что для достаточно больших $n$ отношение $\frac{T(n)}{g(n)}$ стремится к константе $c$. Из определения предела следует, что для любого $\epsilon > 0$ существует $n_0 > 0$, такое что для всех $n \geq n_0$ выполняется: $$\left| \frac{T(n)}{g(n)} - c \right| < \epsilon.$$ Перепишем это неравенство: $$c - \epsilon < \frac{T(n)}{g(n)} < c + \epsilon.$$ Умножим все части на $g(n)$ (при $g(n) > 0$ для достаточно больших $n$): $$(c - \epsilon) g(n) < T(n) < (c + \epsilon) g(n).$$ Выбор $\epsilon$: Пусть $\epsilon = \frac{c}{2}$. Тогда $c - \epsilon = \frac{c}{2}$, а $c + \epsilon = \frac{3c}{2}$. Для всех $n \geq n_0$ получаем: $$\frac{c}{2} g(n) < T(n) < \frac{3c}{2} g(n).$$ Проверка условий $O(g(n))$: Из неравенства выше видно, что: $$T(n) \leq \frac{3c}{2} g(n) \quad \text{для всех } n \geq n_0.$$ Здесь $\frac{3c}{2}$ играет роль константы $C$ в определении $O(g(n))$. Таким образом, $T(n) \in O(g(n))$.


---

### 2. Нижняя граница ($\Omega$-большое, Omega Notation)

**Обозначение $\Omega$-большое** используется для описания нижней границы времени выполнения алгоритма. Оно указывает на наилучший случай выполнения алгоритма.

**Определение**: Функция $T(n)$ принадлежит $\Omega(g(n))$, если существуют такие константы $c > 0$ и $n_0 \geq 1$, что для всех $n \geq n_0$ выполняется: $T(n) \geq c \cdot g(n)$.

Пример: Если $T(n) = 3n^2 + 5n + 7$, то $T(n)$ принадлежит $\Omega(n^2)$, так как можно найти константы $c$ и $n_0$, например $c = 2$ и $n_0 = 1$.

Если $f$ принадлежит $\Omega(g)$, то $g$ принадлежит $O(f)$.

---

### 3. Точная граница (Тета-обозначение, Theta Notation)

**Обозначение Тета** используется для описания точной границы времени выполнения алгоритма, то есть, когда функция одновременно находится в $O(g(n))$ и $\Omega(g(n))$.

**Определение**: Функция $T(n)$ принадлежит $\Theta(g(n))$, если существуют такие константы $c_1 > 0$, $c_2 > 0$ и $n_0 \geq 1$, что для всех $n \geq n_0$ выполняется: $c_1 \cdot g(n) \leq T(n) \leq c_2 \cdot g(n)$.

*Пример*: Если $T(n) = 3n^2 + 5n + 7$, то $T(n)$ принадлежит $\Theta(n^2)$.

---

### 4. Малое $o$ ($o$-большое, Small-o Notation)

**Обозначение $o$-большое** используется для описания верхней границы роста функции, но при этом $T(n)$ растет строго медленнее, чем $g(n)$.

**Определение**: Функция $T(n)$ принадлежит $o(g(n))$, если:

$$
\lim_{n \to \infty} \frac{T(n)}{g(n)} = 0
$$


*Пример*: Если $T(n) = n$, то $T(n)$ принадлежит $o(n^2)$, так как $\lim_{n \to \infty} \frac{n}{n^2} = 0$.

---

### 5. Малое омега ($\omega$-большое, Small-omega Notation)

**Обозначение $\omega$-большое** используется для описания нижней границы роста функции, но при этом $T(n)$ растет строго быстрее, чем $g(n)$.

**Определение**: Функция $T(n)$ принадлежит $\omega(g(n))$, если:

$$
\lim_{n \to \infty} \frac{T(n)}{g(n)} = \infty
$$


Пример: Если $T(n) = n^2$, то $T(n)$ принадлежит $\omega(n)$, так как $\lim_{n \to \infty} \frac{n^2}{n} = \infty$.

---
### Амортизированный анализ
— это метод оценки средней стоимости операций в алгоритме, учитывающий последовательность операций, а не анализ каждой операции в отдельности. Он полезен для алгоритмов, где отдельные операции могут быть дорогими, но в среднем по последовательности операций их стоимость оказывается низкой.

*пример*:
`push_back` в Vector
амортизировано: O(1), 
в худшем случае: O(n).